{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 1.6765953\n",
      "200 0.50610375\n",
      "300 0.46278116\n",
      "400 0.44215935\n",
      "500 0.4064795\n",
      "600 0.39911434\n",
      "700 0.39510894\n",
      "800 0.38579777\n",
      "900 0.37930393\n",
      "1000 0.3741825\n",
      "1100 0.3698694\n",
      "1200 0.36608878\n",
      "1300 0.3627532\n",
      "1400 0.35992968\n",
      "1500 0.3574072\n",
      "1600 0.3552082\n",
      "1700 0.35314816\n",
      "1800 0.35132346\n",
      "1900 0.34975645\n",
      "2000 0.34811756\n",
      "2100 0.34470302\n",
      "2200 0.33886868\n",
      "2300 0.3345167\n",
      "2400 0.33155018\n",
      "2500 0.32941514\n",
      "2600 0.32775953\n",
      "2700 0.326368\n",
      "2800 0.32515943\n",
      "2900 0.32411647\n",
      "3000 0.32318637\n",
      "3100 0.32231545\n",
      "3200 0.32152689\n",
      "3300 0.32080877\n",
      "3400 0.32013866\n",
      "3500 0.31953183\n",
      "3600 0.31898034\n",
      "3700 0.31847015\n",
      "3800 0.3180005\n",
      "3900 0.31755474\n",
      "4000 0.3171463\n",
      "4100 0.31675503\n",
      "4200 0.31640235\n",
      "4300 0.3160695\n",
      "4400 0.3157371\n",
      "4500 0.31543806\n",
      "4600 0.3151512\n",
      "4700 0.3148508\n",
      "4800 0.31456667\n",
      "4900 0.3142923\n",
      "5000 0.31403866\n",
      "5100 0.31378385\n",
      "5200 0.31353822\n",
      "5300 0.31330204\n",
      "5400 0.3130976\n",
      "5500 0.31288576\n",
      "5600 0.3126807\n",
      "5700 0.31247914\n",
      "5800 0.31229442\n",
      "5900 0.31211582\n",
      "6000 0.3119459\n",
      "6100 0.31178147\n",
      "6200 0.3116236\n",
      "6300 0.31146735\n",
      "6400 0.31131506\n",
      "6500 0.31116855\n",
      "6600 0.31102726\n",
      "6700 0.31088936\n",
      "6800 0.3107522\n",
      "6900 0.31061694\n",
      "7000 0.3104798\n",
      "7100 0.3103344\n",
      "7200 0.3101969\n",
      "7300 0.31005406\n",
      "7400 0.309925\n",
      "7500 0.3098017\n",
      "7600 0.3096778\n",
      "7700 0.30955505\n",
      "7800 0.3094366\n",
      "7900 0.30931708\n",
      "8000 0.30919915\n",
      "8100 0.30908456\n",
      "8200 0.30897528\n",
      "8300 0.30886704\n",
      "8400 0.30875728\n",
      "8500 0.3086428\n",
      "8600 0.30853754\n",
      "8700 0.30843714\n",
      "8800 0.30833858\n",
      "8900 0.3082435\n",
      "9000 0.30813608\n",
      "9100 0.3080343\n",
      "9200 0.3079296\n",
      "9300 0.3078244\n",
      "9400 0.30772573\n",
      "9500 0.30762994\n",
      "9600 0.3075383\n",
      "9700 0.30745187\n",
      "9800 0.30736747\n",
      "9900 0.3072873\n",
      "10000 0.30720899\n",
      "10100 0.30712736\n",
      "10200 0.307051\n",
      "10300 0.30697718\n",
      "10400 0.30689967\n",
      "10500 0.30682674\n",
      "10600 0.3067564\n",
      "10700 0.30668682\n",
      "10800 0.3066172\n",
      "10900 0.3065496\n",
      "11000 0.30648258\n",
      "11100 0.30641836\n",
      "11200 0.30635613\n",
      "11300 0.30629534\n",
      "11400 0.30623645\n",
      "11500 0.30617952\n",
      "11600 0.30612344\n",
      "11700 0.30606872\n",
      "11800 0.30601546\n",
      "11900 0.30596358\n",
      "12000 0.3059125\n",
      "12100 0.30586055\n",
      "12200 0.30580792\n",
      "12300 0.30575264\n",
      "12400 0.30569926\n",
      "12500 0.3056501\n",
      "12600 0.30560225\n",
      "12700 0.30555397\n",
      "12800 0.30549774\n",
      "12900 0.30543733\n",
      "13000 0.30538076\n",
      "13100 0.30533358\n",
      "13200 0.30528766\n",
      "13300 0.30523258\n",
      "13400 0.30518878\n",
      "13500 0.30514693\n",
      "13600 0.30510405\n",
      "13700 0.30505463\n",
      "13800 0.30500865\n",
      "13900 0.30496052\n",
      "14000 0.30491653\n",
      "14100 0.30487296\n",
      "14200 0.3048346\n",
      "14300 0.304797\n",
      "14400 0.30476075\n",
      "14500 0.30472124\n",
      "14600 0.30468306\n",
      "14700 0.3046473\n",
      "14800 0.30461296\n",
      "14900 0.30457854\n",
      "15000 0.30454215\n",
      "15100 0.30450487\n",
      "15200 0.3044709\n",
      "15300 0.3044375\n",
      "15400 0.30440456\n",
      "15500 0.3043701\n",
      "15600 0.3043378\n",
      "15700 0.30430746\n",
      "15800 0.30427742\n",
      "15900 0.3042486\n",
      "16000 0.30422074\n",
      "16100 0.30419236\n",
      "16200 0.30416435\n",
      "16300 0.30413583\n",
      "16400 0.3041084\n",
      "16500 0.30408046\n",
      "16600 0.30405346\n",
      "16700 0.30402705\n",
      "16800 0.30400205\n",
      "16900 0.30397776\n",
      "17000 0.30395365\n",
      "17100 0.30392942\n",
      "17200 0.30390596\n",
      "17300 0.30388266\n",
      "17400 0.30386\n",
      "17500 0.30383727\n",
      "17600 0.30381417\n",
      "17700 0.3037911\n",
      "17800 0.30376709\n",
      "17900 0.30374327\n",
      "18000 0.30372027\n",
      "18100 0.30369747\n",
      "18200 0.3036735\n",
      "18300 0.3036479\n",
      "18400 0.3036229\n",
      "18500 0.30359977\n",
      "18600 0.3035778\n",
      "18700 0.3035554\n",
      "18800 0.3035332\n",
      "18900 0.3035109\n",
      "19000 0.3034892\n",
      "19100 0.30346864\n",
      "19200 0.3034491\n",
      "19300 0.30342972\n",
      "19400 0.30341092\n",
      "19500 0.30339238\n",
      "19600 0.30337432\n",
      "19700 0.30335653\n",
      "19800 0.30333894\n",
      "19900 0.30332133\n",
      "20000 0.3033043\n",
      "20100 0.30328774\n",
      "20200 0.30327114\n",
      "20300 0.3032546\n",
      "20400 0.30323806\n",
      "20500 0.30322105\n",
      "20600 0.30320224\n",
      "20700 0.30318516\n",
      "20800 0.30316946\n",
      "20900 0.30315363\n",
      "21000 0.3031382\n",
      "21100 0.30312288\n",
      "21200 0.3031071\n",
      "21300 0.30309135\n",
      "21400 0.30307463\n",
      "21500 0.3030564\n",
      "21600 0.3030401\n",
      "21700 0.3030219\n",
      "21800 0.30300236\n",
      "21900 0.30298445\n",
      "22000 0.30296767\n",
      "22100 0.30295235\n",
      "22200 0.30293775\n",
      "22300 0.30292374\n",
      "22400 0.30291006\n",
      "22500 0.3028965\n",
      "22600 0.30288303\n",
      "22700 0.30286974\n",
      "22800 0.30285698\n",
      "22900 0.3028442\n",
      "23000 0.30283153\n",
      "23100 0.30281913\n",
      "23200 0.3028069\n",
      "23300 0.30279422\n",
      "23400 0.30278227\n",
      "23500 0.30277023\n",
      "23600 0.30275816\n",
      "23700 0.30274636\n",
      "23800 0.30273452\n",
      "23900 0.30272266\n",
      "24000 0.30271092\n",
      "24100 0.30269942\n",
      "24200 0.30268827\n",
      "24300 0.30267692\n",
      "24400 0.3026657\n",
      "24500 0.3026548\n",
      "24600 0.30264375\n",
      "24700 0.30263305\n",
      "24800 0.30262244\n",
      "24900 0.30261195\n",
      "25000 0.30260184\n",
      "25100 0.3025917\n",
      "25200 0.30258173\n",
      "25300 0.3025718\n",
      "25400 0.30256188\n",
      "25500 0.3025518\n",
      "25600 0.30254197\n",
      "25700 0.30253208\n",
      "25800 0.3025218\n",
      "25900 0.3025121\n",
      "26000 0.30250236\n",
      "26100 0.30249283\n",
      "26200 0.30248323\n",
      "26300 0.30247346\n",
      "26400 0.30246398\n",
      "26500 0.30245438\n",
      "26600 0.30244493\n",
      "26700 0.30243596\n",
      "26800 0.30242646\n",
      "26900 0.30241734\n",
      "27000 0.30240765\n",
      "27100 0.302398\n",
      "27200 0.30238843\n",
      "27300 0.30237892\n",
      "27400 0.30237004\n",
      "27500 0.30236098\n",
      "27600 0.30235198\n",
      "27700 0.30234185\n",
      "27800 0.30233043\n",
      "27900 0.30232114\n",
      "28000 0.30231264\n",
      "28100 0.30230352\n",
      "28200 0.30229527\n",
      "28300 0.30228707\n",
      "28400 0.30227885\n",
      "28500 0.30227092\n",
      "28600 0.30226302\n",
      "28700 0.30225524\n",
      "28800 0.3022476\n",
      "28900 0.30223992\n",
      "29000 0.30223247\n",
      "29100 0.3022253\n",
      "29200 0.30221787\n",
      "29300 0.30221066\n",
      "29400 0.3022035\n",
      "29500 0.30219644\n",
      "29600 0.30218938\n",
      "29700 0.30218226\n",
      "29800 0.30217505\n",
      "29900 0.3021683\n",
      "30000 0.30216137\n",
      "accuracy: 85.67\n"
     ]
    }
   ],
   "source": [
    "%run kobeshot_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 1.557\n",
      "200 1.525683\n",
      "300 1.5023024\n",
      "400 1.4808166\n",
      "500 1.453868\n",
      "600 1.4254184\n",
      "700 1.4116769\n",
      "800 1.4031876\n",
      "900 1.3962132\n",
      "1000 1.3895113\n",
      "1100 1.3832604\n",
      "1200 1.3770725\n",
      "1300 1.370498\n",
      "1400 1.3644967\n",
      "1500 1.357365\n",
      "1600 1.3489226\n",
      "1700 1.3388522\n",
      "1800 1.3294661\n",
      "1900 1.3219385\n",
      "2000 1.3143688\n",
      "2100 1.3059639\n",
      "2200 1.2975113\n",
      "2300 1.2889857\n",
      "2400 1.2824849\n",
      "2500 1.2760154\n",
      "2600 1.2717017\n",
      "2700 1.2675655\n",
      "2800 1.2636477\n",
      "2900 1.2601196\n",
      "3000 1.2567613\n",
      "3100 1.2528222\n",
      "3200 1.2451131\n",
      "3300 1.2380387\n",
      "3400 1.2341888\n",
      "3500 1.2313809\n",
      "3600 1.228916\n",
      "3700 1.2269813\n",
      "3800 1.2253191\n",
      "3900 1.2238418\n",
      "4000 1.2221994\n",
      "4100 1.2207699\n",
      "4200 1.2195451\n",
      "4300 1.2184595\n",
      "4400 1.2173058\n",
      "4500 1.2158468\n",
      "4600 1.2147359\n",
      "4700 1.2140481\n",
      "4800 1.2133875\n",
      "4900 1.2127398\n",
      "5000 1.2121356\n",
      "5100 1.2115726\n",
      "5200 1.2110515\n",
      "5300 1.2105544\n",
      "5400 1.2100724\n",
      "5500 1.2096035\n",
      "5600 1.2091526\n",
      "5700 1.2087286\n",
      "5800 1.2083262\n",
      "5900 1.2079417\n",
      "6000 1.2075713\n",
      "6100 1.2072123\n",
      "6200 1.2068648\n",
      "6300 1.2065283\n",
      "6400 1.2061988\n",
      "6500 1.2058607\n",
      "6600 1.2055126\n",
      "6700 1.2052003\n",
      "6800 1.2049176\n",
      "6900 1.2046498\n",
      "7000 1.2043906\n",
      "7100 1.2041403\n",
      "7200 1.203895\n",
      "7300 1.203655\n",
      "7400 1.20342\n",
      "7500 1.203188\n",
      "7600 1.2029585\n",
      "7700 1.2027316\n",
      "7800 1.2025045\n",
      "7900 1.2022766\n",
      "8000 1.202047\n",
      "8100 1.201812\n",
      "8200 1.2015678\n",
      "8300 1.2013183\n",
      "8400 1.2010661\n",
      "8500 1.2008085\n",
      "8600 1.2005496\n",
      "8700 1.2002907\n",
      "8800 1.2000281\n",
      "8900 1.1997617\n",
      "9000 1.1994898\n",
      "9100 1.1992098\n",
      "9200 1.1989187\n",
      "9300 1.1986115\n",
      "9400 1.1982871\n",
      "9500 1.1979662\n",
      "9600 1.1976506\n",
      "9700 1.1973349\n",
      "9800 1.1970167\n",
      "9900 1.1966958\n",
      "10000 1.1963744\n",
      "10100 1.1960534\n",
      "10200 1.1957315\n",
      "10300 1.1954076\n",
      "10400 1.1950798\n",
      "10500 1.1947443\n",
      "10600 1.1943984\n",
      "10700 1.1940436\n",
      "10800 1.1936817\n",
      "10900 1.1933112\n",
      "11000 1.1929246\n",
      "11100 1.1925108\n",
      "11200 1.1920723\n",
      "11300 1.1916307\n",
      "11400 1.1911927\n",
      "11500 1.1907576\n",
      "11600 1.1903272\n",
      "11700 1.1898993\n",
      "11800 1.1894685\n",
      "11900 1.189032\n",
      "12000 1.1885905\n",
      "12100 1.188144\n",
      "12200 1.1876947\n",
      "12300 1.1872472\n",
      "12400 1.186803\n",
      "12500 1.1863599\n",
      "12600 1.1859219\n",
      "12700 1.1854951\n",
      "12800 1.1850822\n",
      "12900 1.1846843\n",
      "13000 1.1843076\n",
      "13100 1.1839578\n",
      "13200 1.1836354\n",
      "13300 1.1833347\n",
      "13400 1.1830503\n",
      "13500 1.1827807\n",
      "13600 1.1825286\n",
      "13700 1.1822935\n",
      "13800 1.1820757\n",
      "13900 1.1818733\n",
      "14000 1.1816854\n",
      "14100 1.1815128\n",
      "14200 1.1813519\n",
      "14300 1.1812027\n",
      "14400 1.1810619\n",
      "14500 1.1809299\n",
      "14600 1.1808045\n",
      "14700 1.1806858\n",
      "14800 1.1805724\n",
      "14900 1.1804634\n",
      "15000 1.1803588\n",
      "15100 1.1802573\n",
      "15200 1.1801602\n",
      "15300 1.1800647\n",
      "15400 1.1799728\n",
      "15500 1.1798831\n",
      "15600 1.179795\n",
      "15700 1.1797098\n",
      "15800 1.1796263\n",
      "15900 1.1795449\n",
      "16000 1.1794653\n",
      "16100 1.1793877\n",
      "16200 1.1793116\n",
      "16300 1.179237\n",
      "16400 1.1791639\n",
      "16500 1.1790919\n",
      "16600 1.1790204\n",
      "16700 1.1789508\n",
      "16800 1.178882\n",
      "16900 1.1788137\n",
      "17000 1.178746\n",
      "17100 1.1786802\n",
      "17200 1.1786145\n",
      "17300 1.17855\n",
      "17400 1.178486\n",
      "17500 1.1784232\n",
      "17600 1.1783613\n",
      "17700 1.1783006\n",
      "17800 1.1782409\n",
      "17900 1.1781826\n",
      "18000 1.1781253\n",
      "18100 1.1780677\n",
      "18200 1.1780121\n",
      "18300 1.1779567\n",
      "18400 1.1779029\n",
      "18500 1.1778485\n",
      "18600 1.177796\n",
      "18700 1.1777434\n",
      "18800 1.1776917\n",
      "18900 1.1776406\n",
      "19000 1.17759\n",
      "19100 1.1775398\n",
      "19200 1.1774912\n",
      "19300 1.1774417\n",
      "19400 1.1773937\n",
      "19500 1.1773461\n",
      "19600 1.1772989\n",
      "19700 1.1772531\n",
      "19800 1.1772066\n",
      "19900 1.1771616\n",
      "20000 1.1771172\n",
      "20100 1.1770732\n",
      "20200 1.17703\n",
      "20300 1.1769878\n",
      "20400 1.1769457\n",
      "20500 1.1769041\n",
      "20600 1.1768631\n",
      "20700 1.1768227\n",
      "20800 1.1767828\n",
      "20900 1.1767433\n",
      "21000 1.1767044\n",
      "21100 1.1766659\n",
      "21200 1.1766281\n",
      "21300 1.1765907\n",
      "21400 1.1765544\n",
      "21500 1.1765181\n",
      "21600 1.1764823\n",
      "21700 1.1764475\n",
      "21800 1.1764134\n",
      "21900 1.1763797\n",
      "22000 1.1763465\n",
      "22100 1.1763138\n",
      "22200 1.1762828\n",
      "22300 1.1762512\n",
      "22400 1.1762199\n",
      "22500 1.1761899\n",
      "22600 1.1761601\n",
      "22700 1.1761308\n",
      "22800 1.1761016\n",
      "22900 1.1760732\n",
      "23000 1.1760448\n",
      "23100 1.1760168\n",
      "23200 1.1759894\n",
      "23300 1.1759623\n",
      "23400 1.1759356\n",
      "23500 1.1759093\n",
      "23600 1.1758832\n",
      "23700 1.175858\n",
      "23800 1.1758327\n",
      "23900 1.1758081\n",
      "24000 1.1757839\n",
      "24100 1.1757603\n",
      "24200 1.1757368\n",
      "24300 1.175714\n",
      "24400 1.1756911\n",
      "24500 1.1756688\n",
      "24600 1.175647\n",
      "24700 1.1756254\n",
      "24800 1.1756041\n",
      "24900 1.175583\n",
      "25000 1.1755624\n",
      "25100 1.175542\n",
      "25200 1.175522\n",
      "25300 1.1755018\n",
      "25400 1.1754819\n",
      "25500 1.1754627\n",
      "25600 1.1754438\n",
      "25700 1.1754247\n",
      "25800 1.1754063\n",
      "25900 1.1753873\n",
      "26000 1.1753688\n",
      "26100 1.1753504\n",
      "26200 1.1753325\n",
      "26300 1.1753148\n",
      "26400 1.1752973\n",
      "26500 1.1752795\n",
      "26600 1.1752621\n",
      "26700 1.1752445\n",
      "26800 1.1752275\n",
      "26900 1.1752108\n",
      "27000 1.175194\n",
      "27100 1.1751773\n",
      "27200 1.1751605\n",
      "27300 1.1751438\n",
      "27400 1.175128\n",
      "27500 1.1751119\n",
      "27600 1.1750963\n",
      "27700 1.1750803\n",
      "27800 1.1750648\n",
      "27900 1.1750492\n",
      "28000 1.1750343\n",
      "28100 1.1750193\n",
      "28200 1.1750041\n",
      "28300 1.1749887\n",
      "28400 1.174974\n",
      "28500 1.1749594\n",
      "28600 1.1749444\n",
      "28700 1.1749295\n",
      "28800 1.1749151\n",
      "28900 1.1749004\n",
      "29000 1.1748863\n",
      "29100 1.1748717\n",
      "29200 1.1748575\n",
      "29300 1.1748434\n",
      "29400 1.1748292\n",
      "29500 1.1748149\n",
      "29600 1.1748009\n",
      "29700 1.1747872\n",
      "29800 1.1747732\n",
      "29900 1.1747596\n",
      "30000 1.1747458\n",
      "accuracy: 68.83\n"
     ]
    }
   ],
   "source": [
    "%run kobeshot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.639463\n",
      "200 0.5571978\n",
      "300 0.5158772\n",
      "400 0.4883922\n",
      "500 0.4682296\n",
      "600 0.45246348\n",
      "700 0.43935928\n",
      "800 0.42808974\n",
      "900 0.4183812\n",
      "1000 0.41014835\n",
      "1100 0.4031856\n",
      "1200 0.39692345\n",
      "1300 0.39186043\n",
      "1400 0.3872121\n",
      "1500 0.38250598\n",
      "1600 0.37900227\n",
      "1700 0.37624243\n",
      "1800 0.37381095\n",
      "1900 0.3716429\n",
      "2000 0.36969066\n",
      "2100 0.36792305\n",
      "2200 0.36630917\n",
      "2300 0.3648326\n",
      "2400 0.36347297\n",
      "2500 0.36221382\n",
      "2600 0.36105344\n",
      "2700 0.35997203\n",
      "2800 0.358964\n",
      "2900 0.3580245\n",
      "3000 0.3571448\n",
      "3100 0.35632515\n",
      "3200 0.3555558\n",
      "3300 0.35483283\n",
      "3400 0.35415465\n",
      "3500 0.3535119\n",
      "3600 0.35290736\n",
      "3700 0.352335\n",
      "3800 0.35179308\n",
      "3900 0.3512802\n",
      "4000 0.35079113\n",
      "4100 0.3503259\n",
      "4200 0.3498853\n",
      "4300 0.34946644\n",
      "4400 0.3490611\n",
      "4500 0.34867963\n",
      "4600 0.3483136\n",
      "4700 0.34796196\n",
      "4800 0.34762743\n",
      "4900 0.34730336\n",
      "5000 0.34699336\n",
      "5100 0.34669665\n",
      "5200 0.34639502\n",
      "5300 0.34611553\n",
      "5400 0.345849\n",
      "5500 0.34559178\n",
      "5600 0.34534416\n",
      "5700 0.34510678\n",
      "5800 0.34487447\n",
      "5900 0.34465498\n",
      "6000 0.3444418\n",
      "6100 0.34423712\n",
      "6200 0.3440421\n",
      "6300 0.34384844\n",
      "6400 0.343664\n",
      "6500 0.34348106\n",
      "6600 0.34325498\n",
      "6700 0.34301335\n",
      "6800 0.34276983\n",
      "6900 0.3425622\n",
      "7000 0.3423661\n",
      "7100 0.34219748\n",
      "7200 0.34204125\n",
      "7300 0.34189358\n",
      "7400 0.3417481\n",
      "7500 0.34158546\n",
      "7600 0.34144658\n",
      "7700 0.34131303\n",
      "7800 0.34117952\n",
      "7900 0.34105468\n",
      "8000 0.34093267\n",
      "8100 0.34081265\n",
      "8200 0.34069714\n",
      "8300 0.34058693\n",
      "8400 0.34047243\n",
      "8500 0.34033996\n",
      "8600 0.3402306\n",
      "8700 0.34012413\n",
      "8800 0.3400168\n",
      "8900 0.339915\n",
      "9000 0.3398126\n",
      "9100 0.33971623\n",
      "9200 0.33961603\n",
      "9300 0.339514\n",
      "9400 0.33942223\n",
      "9500 0.33933055\n",
      "9600 0.33924365\n",
      "9700 0.33915544\n",
      "9800 0.33906874\n",
      "9900 0.33898318\n",
      "10000 0.33890152\n",
      "10100 0.33882284\n",
      "10200 0.3387407\n",
      "10300 0.33865508\n",
      "10400 0.3385421\n",
      "10500 0.33845836\n",
      "10600 0.33838356\n",
      "10700 0.33830574\n",
      "10800 0.3382289\n",
      "10900 0.3381513\n",
      "11000 0.33807632\n",
      "11100 0.33800524\n",
      "11200 0.33793578\n",
      "11300 0.33787316\n",
      "11400 0.3378123\n",
      "11500 0.3377511\n",
      "11600 0.33769396\n",
      "11700 0.3376349\n",
      "11800 0.3375796\n",
      "11900 0.33752692\n",
      "12000 0.337475\n",
      "12100 0.33742326\n",
      "12200 0.33737478\n",
      "12300 0.33732498\n",
      "12400 0.3372742\n",
      "12500 0.3372299\n",
      "12600 0.33717903\n",
      "12700 0.337136\n",
      "12800 0.33709314\n",
      "12900 0.33704838\n",
      "13000 0.33700708\n",
      "13100 0.33696944\n",
      "13200 0.3369328\n",
      "13300 0.33689326\n",
      "13400 0.33685833\n",
      "13500 0.33682162\n",
      "13600 0.33678705\n",
      "13700 0.33675143\n",
      "13800 0.33670998\n",
      "13900 0.33665955\n",
      "14000 0.33654365\n",
      "14100 0.33644307\n",
      "14200 0.3364024\n",
      "14300 0.33635575\n",
      "14400 0.3362873\n",
      "14500 0.33624837\n",
      "14600 0.33621162\n",
      "14700 0.33616498\n",
      "14800 0.33609363\n",
      "14900 0.33602127\n",
      "15000 0.3359755\n",
      "15100 0.33589396\n",
      "15200 0.3357833\n",
      "15300 0.3357324\n",
      "15400 0.33569485\n",
      "15500 0.33565828\n",
      "15600 0.3356213\n",
      "15700 0.33559126\n",
      "15800 0.33555973\n",
      "15900 0.33553195\n",
      "16000 0.33550286\n",
      "16100 0.33547673\n",
      "16200 0.3354493\n",
      "16300 0.3354224\n",
      "16400 0.3353981\n",
      "16500 0.33537388\n",
      "16600 0.3353478\n",
      "16700 0.33532122\n",
      "16800 0.3352983\n",
      "16900 0.3352758\n",
      "17000 0.33525294\n",
      "17100 0.3352302\n",
      "17200 0.33520618\n",
      "17300 0.33518383\n",
      "17400 0.33516183\n",
      "17500 0.3351404\n",
      "17600 0.3351184\n",
      "17700 0.3350982\n",
      "17800 0.3350769\n",
      "17900 0.3350541\n",
      "18000 0.33503625\n",
      "18100 0.3350152\n",
      "18200 0.3349934\n",
      "18300 0.33497646\n",
      "18400 0.33495414\n",
      "18500 0.3349374\n",
      "18600 0.33491588\n",
      "18700 0.33489794\n",
      "18800 0.33487988\n",
      "18900 0.33485973\n",
      "19000 0.3348416\n",
      "19100 0.33482188\n",
      "19200 0.33480322\n",
      "19300 0.33478588\n",
      "19400 0.33476722\n",
      "19500 0.33474827\n",
      "19600 0.33473262\n",
      "19700 0.33471397\n",
      "19800 0.33469743\n",
      "19900 0.33468017\n",
      "20000 0.33466178\n",
      "20100 0.3346467\n",
      "20200 0.33463666\n",
      "20300 0.33461544\n",
      "20400 0.33459955\n",
      "20500 0.3345837\n",
      "20600 0.33456954\n",
      "20700 0.33455077\n",
      "20800 0.33453643\n",
      "20900 0.33452126\n",
      "21000 0.33450603\n",
      "21100 0.33448973\n",
      "21200 0.33447614\n",
      "21300 0.33446005\n",
      "21400 0.3344485\n",
      "21500 0.33443245\n",
      "21600 0.33442\n",
      "21700 0.33440417\n",
      "21800 0.33438972\n",
      "21900 0.33437705\n",
      "22000 0.33436343\n",
      "22100 0.33434668\n",
      "22200 0.33433452\n",
      "22300 0.33432126\n",
      "22400 0.33430716\n",
      "22500 0.33429456\n",
      "22600 0.33428186\n",
      "22700 0.33426815\n",
      "22800 0.33425444\n",
      "22900 0.33424214\n",
      "23000 0.33423093\n",
      "23100 0.33421835\n",
      "23200 0.3342042\n",
      "23300 0.3341885\n",
      "23400 0.33417633\n",
      "23500 0.33416462\n",
      "23600 0.33415297\n",
      "23700 0.33413953\n",
      "23800 0.33412808\n",
      "23900 0.334118\n",
      "24000 0.33410597\n",
      "24100 0.3340951\n",
      "24200 0.3340837\n",
      "24300 0.33407104\n",
      "24400 0.3340601\n",
      "24500 0.33404893\n",
      "24600 0.33403745\n",
      "24700 0.33403084\n",
      "24800 0.33401775\n",
      "24900 0.33400878\n",
      "25000 0.333997\n",
      "25100 0.33398506\n",
      "25200 0.33397716\n",
      "25300 0.33396518\n",
      "25400 0.33395565\n",
      "25500 0.33394414\n",
      "25600 0.33393446\n",
      "25700 0.33392435\n",
      "25800 0.3339146\n",
      "25900 0.33390442\n",
      "26000 0.333897\n",
      "26100 0.3338866\n",
      "26200 0.33387703\n",
      "26300 0.3338663\n",
      "26400 0.33385712\n",
      "26500 0.33384955\n",
      "26600 0.3338373\n",
      "26700 0.33382896\n",
      "26800 0.3338208\n",
      "26900 0.3338112\n",
      "27000 0.33379918\n",
      "27100 0.33379123\n",
      "27200 0.3337832\n",
      "27300 0.3337733\n",
      "27400 0.3337631\n",
      "27500 0.33375362\n",
      "27600 0.3337447\n",
      "27700 0.33373824\n",
      "27800 0.33372873\n",
      "27900 0.33371925\n",
      "28000 0.33371213\n",
      "28100 0.333703\n",
      "28200 0.33369318\n",
      "28300 0.33368525\n",
      "28400 0.33367974\n",
      "28500 0.33367133\n",
      "28600 0.33366325\n",
      "28700 0.33365464\n",
      "28800 0.33364776\n",
      "28900 0.33364\n",
      "29000 0.3336317\n",
      "29100 0.33362567\n",
      "29200 0.33361518\n",
      "29300 0.33360517\n",
      "29400 0.33359915\n",
      "29500 0.33359045\n",
      "29600 0.33358547\n",
      "29700 0.33357745\n",
      "29800 0.33356884\n",
      "29900 0.33356267\n",
      "30000 0.33355254\n",
      "accuracy: 85.50\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed May 16 19:47:19 2018\n",
    "\n",
    "@author: z\n",
    "\n",
    "using CNN\n",
    "\"\"\"\n",
    "\n",
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = pd.read_csv('kobe_data.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs'])\n",
    "\n",
    "x_data = x_data.values\n",
    "y_data = pd.read_csv('kobe_data.csv',usecols=['t1','t2','t3','t4','t5','t6'])\n",
    "y_data = y_data.values\n",
    "\n",
    "x_test = x_data[30000:30600,:]\n",
    "y_test = y_data[30000:30600,:]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([5, 5], -1., 1.))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([5, 6], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]))\n",
    "\n",
    "b2 = tf.Variable(tf.zeros([6]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(30000):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if (step + 1) % 100 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "\n",
    "#print('Predicted value:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "#print('Actual value:', sess.run(target, feed_dict={Y: y_test}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('accuracy: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.66172236\n",
      "200 0.50853115\n",
      "300 0.4502756\n",
      "400 0.4227604\n",
      "500 0.4071593\n",
      "600 0.39693475\n",
      "700 0.3894647\n",
      "800 0.38353556\n",
      "900 0.37859368\n",
      "1000 0.3743458\n",
      "1100 0.37059972\n",
      "1200 0.3672488\n",
      "1300 0.36424446\n",
      "1400 0.36155993\n",
      "1500 0.35917127\n",
      "1600 0.3570446\n",
      "1700 0.35516876\n",
      "1800 0.35351595\n",
      "1900 0.35214344\n",
      "2000 0.3509253\n",
      "2100 0.3498269\n",
      "2200 0.34883833\n",
      "2300 0.34795603\n",
      "2400 0.34715772\n",
      "2500 0.34643966\n",
      "2600 0.3457844\n",
      "2700 0.3451879\n",
      "2800 0.34464404\n",
      "2900 0.34414205\n",
      "3000 0.34368017\n",
      "3100 0.3432568\n",
      "3200 0.34285846\n",
      "3300 0.34248647\n",
      "3400 0.34214255\n",
      "3500 0.3418246\n",
      "3600 0.3415252\n",
      "3700 0.34124535\n",
      "3800 0.3409832\n",
      "3900 0.3407373\n",
      "4000 0.34050506\n",
      "4100 0.34028506\n",
      "4200 0.34007683\n",
      "4300 0.33988184\n",
      "4400 0.33969465\n",
      "4500 0.33951727\n",
      "4600 0.3393477\n",
      "4700 0.3391879\n",
      "4800 0.3390358\n",
      "4900 0.33889213\n",
      "5000 0.33875164\n",
      "5100 0.3386204\n",
      "5200 0.33849388\n",
      "5300 0.33837652\n",
      "5400 0.3382619\n",
      "5500 0.33815184\n",
      "5600 0.338044\n",
      "5700 0.33794212\n",
      "5800 0.3378437\n",
      "5900 0.33774844\n",
      "6000 0.33765897\n",
      "6100 0.33757007\n",
      "6200 0.33748713\n",
      "6300 0.3374074\n",
      "6400 0.3373274\n",
      "6500 0.33725283\n",
      "6600 0.33718017\n",
      "6700 0.33711106\n",
      "6800 0.33704332\n",
      "6900 0.33697605\n",
      "7000 0.33691347\n",
      "7100 0.33685464\n",
      "7200 0.33679157\n",
      "7300 0.33673367\n",
      "7400 0.33667514\n",
      "7500 0.3366186\n",
      "7600 0.33656412\n",
      "7700 0.33650815\n",
      "7800 0.3364551\n",
      "7900 0.336403\n",
      "8000 0.33635172\n",
      "8100 0.33630213\n",
      "8200 0.33625388\n",
      "8300 0.336206\n",
      "8400 0.3361587\n",
      "8500 0.33611307\n",
      "8600 0.33606738\n",
      "8700 0.33602378\n",
      "8800 0.3359796\n",
      "8900 0.33593637\n",
      "9000 0.33589453\n",
      "9100 0.33585167\n",
      "9200 0.3358102\n",
      "9300 0.3357684\n",
      "9400 0.3357269\n",
      "9500 0.33568585\n",
      "9600 0.33564597\n",
      "9700 0.33560708\n",
      "9800 0.33556867\n",
      "9900 0.33553106\n",
      "10000 0.33549407\n",
      "10100 0.33545762\n",
      "10200 0.33542222\n",
      "10300 0.3353875\n",
      "10400 0.33535305\n",
      "10500 0.3353189\n",
      "10600 0.33528575\n",
      "10700 0.33525366\n",
      "10800 0.33522126\n",
      "10900 0.33519003\n",
      "11000 0.33515903\n",
      "11100 0.33512852\n",
      "11200 0.3350992\n",
      "11300 0.33506998\n",
      "11400 0.33504105\n",
      "11500 0.33501294\n",
      "11600 0.33498496\n",
      "11700 0.33495754\n",
      "11800 0.33493057\n",
      "11900 0.3349036\n",
      "12000 0.33487746\n",
      "12100 0.3348512\n",
      "12200 0.3348256\n",
      "12300 0.33480042\n",
      "12400 0.3347755\n",
      "12500 0.334751\n",
      "12600 0.33472645\n",
      "12700 0.3347026\n",
      "12800 0.33467895\n",
      "12900 0.33465576\n",
      "13000 0.3346323\n",
      "13100 0.33460915\n",
      "13200 0.33458638\n",
      "13300 0.3345642\n",
      "13400 0.33454224\n",
      "13500 0.33452025\n",
      "13600 0.3344988\n",
      "13700 0.3344771\n",
      "13800 0.33445597\n",
      "13900 0.3344351\n",
      "14000 0.3344147\n",
      "14100 0.33439425\n",
      "14200 0.33437422\n",
      "14300 0.33435425\n",
      "14400 0.33433473\n",
      "14500 0.33431533\n",
      "14600 0.33429605\n",
      "14700 0.33427718\n",
      "14800 0.33425838\n",
      "14900 0.33423963\n",
      "15000 0.3342214\n",
      "15100 0.33420342\n",
      "15200 0.33418557\n",
      "15300 0.33416796\n",
      "15400 0.33415043\n",
      "15500 0.33413348\n",
      "15600 0.3341162\n",
      "15700 0.33409956\n",
      "15800 0.33408284\n",
      "15900 0.3340665\n",
      "16000 0.3340501\n",
      "16100 0.33403417\n",
      "16200 0.33401796\n",
      "16300 0.33400238\n",
      "16400 0.33398676\n",
      "16500 0.33397135\n",
      "16600 0.33395568\n",
      "16700 0.33394018\n",
      "16800 0.33392486\n",
      "16900 0.33390993\n",
      "17000 0.33389482\n",
      "17100 0.3338801\n",
      "17200 0.33386552\n",
      "17300 0.33385083\n",
      "17400 0.3338366\n",
      "17500 0.33382237\n",
      "17600 0.33380845\n",
      "17700 0.3337945\n",
      "17800 0.33378047\n",
      "17900 0.3337666\n",
      "18000 0.33375272\n",
      "18100 0.3337387\n",
      "18200 0.33372492\n",
      "18300 0.33371103\n",
      "18400 0.33369756\n",
      "18500 0.33368418\n",
      "18600 0.3336709\n",
      "18700 0.33365804\n",
      "18800 0.33364505\n",
      "18900 0.33363247\n",
      "19000 0.3336198\n",
      "19100 0.3336072\n",
      "19200 0.33359492\n",
      "19300 0.3335825\n",
      "19400 0.33357036\n",
      "19500 0.3335584\n",
      "19600 0.33354637\n",
      "19700 0.33353436\n",
      "19800 0.3335227\n",
      "19900 0.33351108\n",
      "20000 0.33349955\n",
      "20100 0.33348835\n",
      "20200 0.33347693\n",
      "20300 0.33346543\n",
      "20400 0.33345428\n",
      "20500 0.3334429\n",
      "20600 0.3334321\n",
      "20700 0.333421\n",
      "20800 0.33341023\n",
      "20900 0.333399\n",
      "21000 0.33338797\n",
      "21100 0.3333771\n",
      "21200 0.33336616\n",
      "21300 0.33335534\n",
      "21400 0.3333446\n",
      "21500 0.33333412\n",
      "21600 0.3333237\n",
      "21700 0.33331338\n",
      "21800 0.33330312\n",
      "21900 0.33329296\n",
      "22000 0.3332829\n",
      "22100 0.333273\n",
      "22200 0.33326292\n",
      "22300 0.3332531\n",
      "22400 0.33324337\n",
      "22500 0.3332335\n",
      "22600 0.33322382\n",
      "22700 0.33321413\n",
      "22800 0.33320457\n",
      "22900 0.3331951\n",
      "23000 0.33318552\n",
      "23100 0.3331759\n",
      "23200 0.33316615\n",
      "23300 0.33315632\n",
      "23400 0.3331457\n",
      "23500 0.33313504\n",
      "23600 0.33312458\n",
      "23700 0.33311427\n",
      "23800 0.33310407\n",
      "23900 0.33309406\n",
      "24000 0.33308434\n",
      "24100 0.3330746\n",
      "24200 0.33306524\n",
      "24300 0.3330558\n",
      "24400 0.3330464\n",
      "24500 0.3330372\n",
      "24600 0.33302805\n",
      "24700 0.33301926\n",
      "24800 0.33301026\n",
      "24900 0.33300126\n",
      "25000 0.3329924\n",
      "25100 0.33298364\n",
      "25200 0.33297512\n",
      "25300 0.33296663\n",
      "25400 0.3329583\n",
      "25500 0.33294997\n",
      "25600 0.33294162\n",
      "25700 0.33293372\n",
      "25800 0.3329257\n",
      "25900 0.3329178\n",
      "26000 0.33291\n",
      "26100 0.33290228\n",
      "26200 0.33289436\n",
      "26300 0.33288684\n",
      "26400 0.33287936\n",
      "26500 0.33287194\n",
      "26600 0.3328645\n",
      "26700 0.3328572\n",
      "26800 0.33284974\n",
      "26900 0.3328424\n",
      "27000 0.33283523\n",
      "27100 0.33282822\n",
      "27200 0.33282122\n",
      "27300 0.33281428\n",
      "27400 0.3328073\n",
      "27500 0.33280054\n",
      "27600 0.3327938\n",
      "27700 0.33278713\n",
      "27800 0.33278075\n",
      "27900 0.3327743\n",
      "28000 0.33276764\n",
      "28100 0.33276126\n",
      "28200 0.33275503\n",
      "28300 0.33274868\n",
      "28400 0.33274248\n",
      "28500 0.33273605\n",
      "28600 0.33272982\n",
      "28700 0.33272347\n",
      "28800 0.3327171\n",
      "28900 0.33271107\n",
      "29000 0.3327049\n",
      "29100 0.3326989\n",
      "29200 0.332693\n",
      "29300 0.332687\n",
      "29400 0.3326812\n",
      "29500 0.3326754\n",
      "29600 0.33266938\n",
      "29700 0.3326631\n",
      "29800 0.33265725\n",
      "29900 0.33265126\n",
      "30000 0.33264515\n",
      "accuracy: 86.00\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed May 16 19:47:19 2018\n",
    "\n",
    "@author: z\n",
    "\n",
    "using CNN\n",
    "\"\"\"\n",
    "\n",
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = pd.read_csv('kobe_data.csv',usecols=['shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x_data = x_data.values\n",
    "y_data = pd.read_csv('kobe_data.csv',usecols=['t1','t2','t3','t4','t5','t6'])\n",
    "y_data = y_data.values\n",
    "\n",
    "x_test = x_data[30000:30600,:]\n",
    "y_test = y_data[30000:30600,:]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([7, 9], -1., 1.))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([9, 6], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([9]))\n",
    "\n",
    "b2 = tf.Variable(tf.zeros([6]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(30000):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if (step + 1) % 100 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "\n",
    "#print('Predicted value:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "#print('Actual value:', sess.run(target, feed_dict={Y: y_test}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('accuracy: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 1.0763427\n",
      "200 0.680093\n",
      "300 0.54924375\n",
      "400 0.48282358\n",
      "500 0.43828353\n",
      "600 0.4093338\n",
      "700 0.39036623\n",
      "800 0.3787408\n",
      "900 0.37119833\n",
      "1000 0.36650062\n",
      "1100 0.36318222\n",
      "1200 0.3606838\n",
      "1300 0.35896274\n",
      "1400 0.35751918\n",
      "1500 0.35640043\n",
      "1600 0.35528916\n",
      "1700 0.35443318\n",
      "1800 0.35364288\n",
      "1900 0.3529409\n",
      "2000 0.35233837\n",
      "2100 0.35170856\n",
      "2200 0.35104555\n",
      "2300 0.35056773\n",
      "2400 0.35007846\n",
      "2500 0.34984812\n",
      "2600 0.34937114\n",
      "2700 0.34880555\n",
      "2800 0.3483169\n",
      "2900 0.34784952\n",
      "3000 0.34740946\n",
      "3100 0.34696358\n",
      "3200 0.34649757\n",
      "3300 0.34609422\n",
      "3400 0.34571642\n",
      "3500 0.34540612\n",
      "3600 0.34503737\n",
      "3700 0.34452468\n",
      "3800 0.3440554\n",
      "3900 0.34359097\n",
      "4000 0.34312728\n",
      "4100 0.34256274\n",
      "4200 0.34200868\n",
      "4300 0.34135398\n",
      "4400 0.3406671\n",
      "4500 0.33946618\n",
      "4600 0.33810726\n",
      "4700 0.3365899\n",
      "4800 0.33558148\n",
      "4900 0.33483288\n",
      "5000 0.33411875\n",
      "5100 0.33334306\n",
      "5200 0.33279943\n",
      "5300 0.33223277\n",
      "5400 0.33153743\n",
      "5500 0.330995\n",
      "5600 0.33047533\n",
      "5700 0.33007786\n",
      "5800 0.32975468\n",
      "5900 0.32937142\n",
      "6000 0.32916018\n",
      "6100 0.32914445\n",
      "6200 0.3286531\n",
      "6300 0.32823923\n",
      "6400 0.3279235\n",
      "6500 0.3275187\n",
      "6600 0.32724115\n",
      "6700 0.32704967\n",
      "6800 0.32675898\n",
      "6900 0.32644212\n",
      "7000 0.32609776\n",
      "7100 0.3258839\n",
      "7200 0.32562706\n",
      "7300 0.3254292\n",
      "7400 0.3253072\n",
      "7500 0.325063\n",
      "7600 0.32470304\n",
      "7700 0.32441354\n",
      "7800 0.32406545\n",
      "7900 0.3238506\n",
      "8000 0.32362995\n",
      "8100 0.32340235\n",
      "8200 0.3232724\n",
      "8300 0.3229752\n",
      "8400 0.32273445\n",
      "8500 0.32252988\n",
      "8600 0.32225493\n",
      "8700 0.32216626\n",
      "8800 0.32196435\n",
      "8900 0.3216718\n",
      "9000 0.32160342\n",
      "9100 0.3212934\n",
      "9200 0.321068\n",
      "9300 0.32087395\n",
      "9400 0.32067525\n",
      "9500 0.3204749\n",
      "9600 0.32038316\n",
      "9700 0.3201942\n",
      "9800 0.3199524\n",
      "9900 0.31977126\n",
      "10000 0.31958237\n",
      "10100 0.31941995\n",
      "10200 0.31932926\n",
      "10300 0.31912598\n",
      "10400 0.31903774\n",
      "10500 0.3189194\n",
      "10600 0.31890428\n",
      "10700 0.31886047\n",
      "10800 0.3185837\n",
      "10900 0.3184609\n",
      "11000 0.31838533\n",
      "11100 0.3182489\n",
      "11200 0.31805256\n",
      "11300 0.31798744\n",
      "11400 0.3178501\n",
      "11500 0.3177923\n",
      "11600 0.31767985\n",
      "11700 0.3175578\n",
      "11800 0.3174154\n",
      "11900 0.31736162\n",
      "12000 0.3171846\n",
      "12100 0.31706825\n",
      "12200 0.3169949\n",
      "12300 0.3168497\n",
      "12400 0.3166962\n",
      "12500 0.31657434\n",
      "12600 0.31650826\n",
      "12700 0.31642967\n",
      "12800 0.3164229\n",
      "12900 0.31636247\n",
      "13000 0.31614685\n",
      "13100 0.3161003\n",
      "13200 0.31607962\n",
      "13300 0.31607342\n",
      "13400 0.31597\n",
      "13500 0.31600645\n",
      "13600 0.3159342\n",
      "13700 0.31579167\n",
      "13800 0.31594765\n",
      "13900 0.31585932\n",
      "14000 0.3157448\n",
      "14100 0.31567\n",
      "14200 0.31555068\n",
      "14300 0.3155486\n",
      "14400 0.3154259\n",
      "14500 0.31545958\n",
      "14600 0.315313\n",
      "14700 0.31538874\n",
      "14800 0.31530333\n",
      "14900 0.3152528\n",
      "15000 0.31535533\n",
      "15100 0.3151961\n",
      "15200 0.31515908\n",
      "15300 0.31509286\n",
      "15400 0.31501585\n",
      "15500 0.31498674\n",
      "15600 0.31490704\n",
      "15700 0.31484407\n",
      "15800 0.3147459\n",
      "15900 0.3146763\n",
      "16000 0.3146043\n",
      "16100 0.31455702\n",
      "16200 0.31450325\n",
      "16300 0.3144388\n",
      "16400 0.31438112\n",
      "16500 0.31436253\n",
      "16600 0.3144182\n",
      "16700 0.31433606\n",
      "16800 0.3143778\n",
      "16900 0.3143484\n",
      "17000 0.31427962\n",
      "17100 0.31424138\n",
      "17200 0.31416184\n",
      "17300 0.31410155\n",
      "17400 0.31394535\n",
      "17500 0.31385273\n",
      "17600 0.31384197\n",
      "17700 0.31380776\n",
      "17800 0.3137855\n",
      "17900 0.3137421\n",
      "18000 0.3137284\n",
      "18100 0.3137014\n",
      "18200 0.31365132\n",
      "18300 0.31365246\n",
      "18400 0.31363803\n",
      "18500 0.31362313\n",
      "18600 0.31362686\n",
      "18700 0.31358016\n",
      "18800 0.31355014\n",
      "18900 0.31355077\n",
      "19000 0.313536\n",
      "19100 0.31349882\n",
      "19200 0.3135074\n",
      "19300 0.31345752\n",
      "19400 0.31342316\n",
      "19500 0.31339374\n",
      "19600 0.31335586\n",
      "19700 0.31339136\n",
      "19800 0.31335178\n",
      "19900 0.3133201\n",
      "20000 0.31327134\n",
      "20100 0.31323346\n",
      "20200 0.31315595\n",
      "20300 0.3131379\n",
      "20400 0.31312543\n",
      "20500 0.31307405\n"
     ]
    }
   ],
   "source": [
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = pd.read_csv('kobe_data.csv',usecols=['shot_distance',\n",
    "'shot_zone_area','period','minutes_remaining','seconds_remaining'])\n",
    "\n",
    "x_data = x_data.values\n",
    "y_data = pd.read_csv('kobe_data.csv',usecols=['t1','t2','t3','t4','t5','t6'])\n",
    "y_data = y_data.values\n",
    "\n",
    "x_test = x_data[30000:30600,:]\n",
    "y_test = y_data[30000:30600,:]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([5, 9], -1., 1.))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([9, 6], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([9]))\n",
    "\n",
    "b2 = tf.Variable(tf.zeros([6]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(30000):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if (step + 1) % 100 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "\n",
    "#print('Predicted value:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "#print('Actual value:', sess.run(target, feed_dict={Y: y_test}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('accuracy: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.7232901\n",
      "200 0.5906161\n",
      "300 0.52671814\n",
      "400 0.487615\n",
      "500 0.4590911\n",
      "600 0.4367727\n",
      "700 0.41863278\n",
      "800 0.40358782\n",
      "900 0.3911649\n",
      "1000 0.38095573\n",
      "1100 0.37264696\n",
      "1200 0.36595994\n",
      "1300 0.36061797\n",
      "1400 0.3563653\n",
      "1500 0.35296482\n",
      "1600 0.350232\n",
      "1700 0.34806275\n",
      "1800 0.34634352\n",
      "1900 0.3449068\n",
      "2000 0.34367427\n",
      "2100 0.34259766\n",
      "2200 0.3416394\n",
      "2300 0.3407713\n",
      "2400 0.33997765\n",
      "2500 0.3392582\n",
      "2600 0.33858934\n",
      "2700 0.33795917\n",
      "2800 0.33736107\n",
      "2900 0.3367904\n",
      "3000 0.3362452\n",
      "3100 0.33572006\n",
      "3200 0.3352157\n",
      "3300 0.33473358\n",
      "3400 0.33426607\n",
      "3500 0.33381295\n",
      "3600 0.33337167\n",
      "3700 0.33294153\n",
      "3800 0.3325218\n",
      "3900 0.3321144\n",
      "4000 0.33171526\n",
      "4100 0.33132833\n",
      "4200 0.33094934\n",
      "4300 0.33057812\n",
      "4400 0.33021697\n",
      "4500 0.32986265\n",
      "4600 0.32951647\n",
      "4700 0.32917792\n",
      "4800 0.3288471\n",
      "4900 0.32852283\n",
      "5000 0.32820582\n",
      "5100 0.3278957\n",
      "5200 0.32759187\n",
      "5300 0.3272949\n",
      "5400 0.32700312\n",
      "5500 0.32672006\n",
      "5600 0.32644248\n",
      "5700 0.32616857\n",
      "5800 0.325901\n",
      "5900 0.32563937\n",
      "6000 0.3253835\n",
      "6100 0.3251299\n",
      "6200 0.32488254\n",
      "6300 0.32464066\n",
      "6400 0.32440227\n",
      "6500 0.32416943\n",
      "6600 0.32394117\n",
      "6700 0.32371736\n",
      "6800 0.32349655\n",
      "6900 0.32328105\n",
      "7000 0.32306892\n",
      "7100 0.32285982\n",
      "7200 0.3226547\n",
      "7300 0.32245314\n",
      "7400 0.3222567\n",
      "7500 0.32206205\n",
      "7600 0.32187206\n",
      "7700 0.32168642\n",
      "7800 0.3215024\n",
      "7900 0.32132328\n",
      "8000 0.32114562\n",
      "8100 0.32097214\n",
      "8200 0.3208013\n",
      "8300 0.32063285\n",
      "8400 0.3204673\n",
      "8500 0.32030633\n",
      "8600 0.32014775\n",
      "8700 0.31999013\n",
      "8800 0.3198354\n",
      "8900 0.31968457\n",
      "9000 0.31953633\n",
      "9100 0.31938744\n",
      "9200 0.31924644\n",
      "9300 0.31910366\n",
      "9400 0.3189668\n",
      "9500 0.31882897\n",
      "9600 0.31869537\n",
      "9700 0.31856358\n",
      "9800 0.31843257\n",
      "9900 0.3183054\n",
      "10000 0.3181799\n",
      "10100 0.31805745\n",
      "10200 0.31793657\n",
      "10300 0.31781787\n",
      "10400 0.3176993\n",
      "10500 0.3175837\n",
      "10600 0.31747088\n",
      "10700 0.31735808\n",
      "10800 0.3172497\n",
      "10900 0.3171403\n",
      "11000 0.31703496\n",
      "11100 0.31692988\n",
      "11200 0.3168276\n",
      "11300 0.31672722\n",
      "11400 0.3166275\n",
      "11500 0.31652978\n",
      "11600 0.31643388\n",
      "11700 0.3163413\n",
      "11800 0.31624943\n",
      "11900 0.31615832\n",
      "12000 0.3160681\n",
      "12100 0.31598037\n",
      "12200 0.3158942\n",
      "12300 0.31580946\n",
      "12400 0.31572694\n",
      "12500 0.31564507\n",
      "12600 0.31556433\n",
      "12700 0.3154844\n",
      "12800 0.31540573\n",
      "12900 0.31533083\n",
      "13000 0.31525463\n",
      "13100 0.31518155\n",
      "13200 0.3151094\n",
      "13300 0.31503755\n",
      "13400 0.3149674\n",
      "13500 0.3148998\n",
      "13600 0.31483063\n",
      "13700 0.31476367\n",
      "13800 0.3146979\n",
      "13900 0.3146341\n",
      "14000 0.31457093\n",
      "14100 0.3145087\n",
      "14200 0.314448\n",
      "14300 0.31438756\n",
      "14400 0.3143288\n",
      "14500 0.3142717\n",
      "14600 0.314215\n",
      "14700 0.31416017\n",
      "14800 0.31410497\n",
      "14900 0.31404927\n",
      "15000 0.31399763\n",
      "15100 0.3139471\n",
      "15200 0.31389573\n",
      "15300 0.3138455\n",
      "15400 0.3137968\n",
      "15500 0.31374857\n",
      "15600 0.31370115\n",
      "15700 0.3136542\n",
      "15800 0.3136082\n",
      "15900 0.31356373\n",
      "16000 0.3135195\n",
      "16100 0.3134748\n",
      "16200 0.31343168\n",
      "16300 0.3133892\n",
      "16400 0.31334662\n",
      "16500 0.3133062\n",
      "16600 0.31326416\n",
      "16700 0.31322432\n",
      "16800 0.31318465\n",
      "16900 0.31314585\n",
      "17000 0.31310874\n",
      "17100 0.313071\n",
      "17200 0.31303316\n",
      "17300 0.3129965\n",
      "17400 0.31296012\n",
      "17500 0.31292555\n",
      "17600 0.31289056\n",
      "17700 0.3128555\n",
      "17800 0.31282058\n",
      "17900 0.31278792\n",
      "18000 0.31275493\n",
      "18100 0.31272137\n",
      "18200 0.31269017\n",
      "18300 0.31265813\n",
      "18400 0.31262615\n",
      "18500 0.3125944\n",
      "18600 0.31256455\n",
      "18700 0.31253484\n",
      "18800 0.31250557\n",
      "18900 0.31247514\n",
      "19000 0.31244668\n",
      "19100 0.3124171\n",
      "19200 0.31238827\n",
      "19300 0.31236047\n",
      "19400 0.31233317\n",
      "19500 0.3123048\n",
      "19600 0.3122777\n",
      "19700 0.3122516\n",
      "19800 0.31222573\n",
      "19900 0.31219906\n",
      "20000 0.31217384\n",
      "20100 0.31214863\n",
      "20200 0.3121217\n",
      "20300 0.31209743\n",
      "20400 0.3120737\n",
      "20500 0.31204844\n",
      "20600 0.31202465\n",
      "20700 0.31200105\n",
      "20800 0.31197676\n",
      "20900 0.31195453\n",
      "21000 0.31193033\n",
      "21100 0.31190786\n",
      "21200 0.3118848\n",
      "21300 0.31186235\n",
      "21400 0.31184047\n",
      "21500 0.31181774\n",
      "21600 0.31179667\n",
      "21700 0.3117755\n",
      "21800 0.31175503\n",
      "21900 0.3117327\n",
      "22000 0.31171212\n",
      "22100 0.31169084\n",
      "22200 0.31167072\n",
      "22300 0.31164962\n",
      "22400 0.31162974\n",
      "22500 0.311611\n",
      "22600 0.31159088\n",
      "22700 0.3115712\n",
      "22800 0.31155163\n",
      "22900 0.31153196\n",
      "23000 0.31151354\n",
      "23100 0.3114956\n",
      "23200 0.31147534\n",
      "23300 0.31145674\n",
      "23400 0.31143728\n",
      "23500 0.31141922\n",
      "23600 0.31140196\n",
      "23700 0.31138346\n",
      "23800 0.31136656\n",
      "23900 0.3113484\n",
      "24000 0.31133053\n",
      "24100 0.3113139\n",
      "24200 0.3112963\n",
      "24300 0.3112791\n",
      "24400 0.3112616\n",
      "24500 0.31124473\n",
      "24600 0.31122887\n",
      "24700 0.31121224\n",
      "24800 0.31119573\n",
      "24900 0.3111792\n",
      "25000 0.31116265\n",
      "25100 0.31114668\n",
      "25200 0.31113285\n",
      "25300 0.31111613\n",
      "25400 0.31110096\n",
      "25500 0.31108522\n",
      "25600 0.31106836\n",
      "25700 0.311053\n",
      "25800 0.31103864\n",
      "25900 0.31102324\n",
      "26000 0.31100667\n",
      "26100 0.31099218\n",
      "26200 0.3109773\n",
      "26300 0.31096202\n",
      "26400 0.31094763\n",
      "26500 0.31093302\n",
      "26600 0.31091812\n",
      "26700 0.310904\n",
      "26800 0.31089026\n",
      "26900 0.31087613\n",
      "27000 0.3108613\n",
      "27100 0.31084806\n",
      "27200 0.31083414\n",
      "27300 0.31081924\n",
      "27400 0.3108049\n",
      "27500 0.3107919\n",
      "27600 0.3107768\n",
      "27700 0.31076422\n",
      "27800 0.31075063\n",
      "27900 0.31073797\n",
      "28000 0.31072408\n",
      "28100 0.31071177\n",
      "28200 0.3106967\n",
      "28300 0.31068498\n",
      "28400 0.31067142\n",
      "28500 0.3106578\n",
      "28600 0.3106464\n",
      "28700 0.31063342\n",
      "28800 0.31062052\n",
      "28900 0.31060824\n",
      "29000 0.31059533\n",
      "29100 0.3105831\n",
      "29200 0.3105708\n",
      "29300 0.31055745\n",
      "29400 0.31054547\n",
      "29500 0.31053308\n",
      "29600 0.31052133\n",
      "29700 0.31050926\n",
      "29800 0.31049553\n",
      "29900 0.31048474\n",
      "30000 0.31047338\n",
      "accuracy: 86.00\n"
     ]
    }
   ],
   "source": [
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = pd.read_csv('kobe_data.csv',usecols=['shot_distance','shot_zone_area','period'])\n",
    "\n",
    "x_data = x_data.values\n",
    "y_data = pd.read_csv('kobe_data.csv',usecols=['t1','t2','t3','t4','t5','t6'])\n",
    "y_data = y_data.values\n",
    "\n",
    "x_test = x_data[30000:30600,:]\n",
    "y_test = y_data[30000:30600,:]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([3, 5], -1., 1.))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([5, 6], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]))\n",
    "\n",
    "b2 = tf.Variable(tf.zeros([6]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(30000):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if (step + 1) % 100 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "\n",
    "#print('Predicted value:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "#print('Actual value:', sess.run(target, feed_dict={Y: y_test}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('accuracy: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.6539798\n",
      "200 0.53434026\n",
      "300 0.47081205\n",
      "400 0.47884414\n",
      "500 0.43691474\n",
      "600 0.4346113\n",
      "700 0.4150166\n",
      "800 0.42153683\n",
      "900 0.4269739\n",
      "1000 0.39798802\n",
      "1100 0.39109156\n",
      "1200 0.38615635\n",
      "1300 0.3772827\n",
      "1400 0.3733581\n",
      "1500 0.3719165\n",
      "1600 0.37070006\n",
      "1700 0.36342886\n",
      "1800 0.35897776\n",
      "1900 0.35845068\n",
      "2000 0.35352504\n",
      "2100 0.35054275\n",
      "2200 0.3480966\n",
      "2300 0.3477152\n",
      "2400 0.34547904\n",
      "2500 0.34935758\n",
      "2600 0.39172933\n",
      "2700 0.34021595\n",
      "2800 0.33903694\n",
      "2900 0.34413478\n",
      "3000 0.33770683\n",
      "3100 0.3374256\n",
      "3200 0.34352276\n",
      "3300 0.33629823\n",
      "3400 0.33320174\n",
      "3500 0.34405306\n",
      "3600 0.3320653\n",
      "3700 0.32967278\n",
      "3800 0.32833156\n",
      "3900 0.32851216\n",
      "4000 0.3235103\n",
      "4100 0.32309666\n",
      "4200 0.32023263\n",
      "4300 0.3196996\n",
      "4400 0.32081565\n",
      "4500 0.31878513\n",
      "4600 0.3176903\n",
      "4700 0.31717137\n",
      "4800 0.3149257\n",
      "4900 0.3223627\n",
      "5000 0.31485707\n",
      "5100 0.31185493\n",
      "5200 0.31496757\n",
      "5300 0.3104182\n",
      "5400 0.31062117\n",
      "5500 0.31201264\n",
      "5600 0.31002498\n",
      "5700 0.30868354\n",
      "5800 0.30902493\n",
      "5900 0.30867767\n",
      "6000 0.30913794\n",
      "6100 0.30841026\n",
      "6200 0.30742988\n",
      "6300 0.3069958\n",
      "6400 0.30975893\n",
      "6500 0.3098307\n",
      "6600 0.30868885\n",
      "6700 0.3104572\n",
      "6800 0.3069789\n",
      "6900 0.30613983\n",
      "7000 0.31002173\n",
      "7100 0.30903387\n",
      "7200 0.30576733\n",
      "7300 0.30727062\n",
      "7400 0.3070523\n",
      "7500 0.30571076\n",
      "7600 0.3063547\n",
      "7700 0.30583954\n",
      "7800 0.30527073\n",
      "7900 0.30558392\n",
      "8000 0.30515674\n",
      "8100 0.3051839\n",
      "8200 0.3050954\n",
      "8300 0.30500346\n",
      "8400 0.3049465\n",
      "8500 0.30487737\n",
      "8600 0.30480272\n",
      "8700 0.30475217\n",
      "8800 0.30469522\n",
      "8900 0.3046614\n",
      "9000 0.30460367\n",
      "9100 0.30456308\n",
      "9200 0.30453315\n",
      "9300 0.30450305\n",
      "9400 0.30446368\n",
      "9500 0.30446437\n",
      "9600 0.30445826\n",
      "9700 0.30442864\n",
      "9800 0.30440643\n",
      "9900 0.30438322\n",
      "10000 0.3044053\n",
      "10100 0.3044557\n",
      "10200 0.3044319\n",
      "10300 0.30439427\n",
      "10400 0.30433175\n",
      "10500 0.3042731\n",
      "10600 0.30423057\n",
      "10700 0.30415195\n",
      "10800 0.30408135\n",
      "10900 0.30404562\n",
      "11000 0.30402657\n",
      "11100 0.30397964\n",
      "11200 0.3039292\n",
      "11300 0.30392087\n",
      "11400 0.30387825\n",
      "11500 0.30383003\n",
      "11600 0.3037843\n",
      "11700 0.30374587\n",
      "11800 0.30369234\n",
      "11900 0.30365068\n",
      "12000 0.30361447\n",
      "12100 0.30356184\n",
      "12200 0.30353045\n",
      "12300 0.30345464\n",
      "12400 0.3034304\n",
      "12500 0.30340308\n",
      "12600 0.3033809\n",
      "12700 0.30335766\n",
      "12800 0.3033307\n",
      "12900 0.30330306\n",
      "13000 0.3032743\n",
      "13100 0.30325052\n",
      "13200 0.30322897\n",
      "13300 0.3032088\n",
      "13400 0.30318537\n",
      "13500 0.30316594\n",
      "13600 0.30314612\n",
      "13700 0.30313033\n",
      "13800 0.30311534\n",
      "13900 0.3031021\n",
      "14000 0.3030917\n",
      "14100 0.30307654\n",
      "14200 0.3030653\n",
      "14300 0.3031049\n",
      "14400 0.30308613\n",
      "14500 0.30306986\n",
      "14600 0.30305287\n",
      "14700 0.3030433\n",
      "14800 0.30302295\n",
      "14900 0.30303702\n",
      "15000 0.30299723\n",
      "15100 0.30298397\n",
      "15200 0.30295125\n",
      "15300 0.30294135\n",
      "15400 0.30292812\n",
      "15500 0.30291194\n",
      "15600 0.30289555\n",
      "15700 0.3028951\n",
      "15800 0.30290335\n",
      "15900 0.30288836\n",
      "16000 0.30287907\n",
      "16100 0.30286196\n",
      "16200 0.30282995\n",
      "16300 0.30283514\n",
      "16400 0.30283073\n",
      "16500 0.3028145\n",
      "16600 0.3028\n",
      "16700 0.30281097\n",
      "16800 0.30277383\n",
      "16900 0.30276355\n",
      "17000 0.30274913\n",
      "17100 0.30273014\n",
      "17200 0.30271986\n",
      "17300 0.30269834\n",
      "17400 0.30269566\n",
      "17500 0.30268815\n",
      "17600 0.30265892\n",
      "17700 0.30264732\n",
      "17800 0.3026396\n",
      "17900 0.30264273\n",
      "18000 0.302622\n",
      "18100 0.30261433\n",
      "18200 0.30260238\n",
      "18300 0.302607\n",
      "18400 0.302596\n",
      "18500 0.3025816\n",
      "18600 0.3025752\n",
      "18700 0.3025583\n",
      "18800 0.30255175\n",
      "18900 0.30254024\n",
      "19000 0.30253074\n",
      "19100 0.30251873\n",
      "19200 0.30251098\n",
      "19300 0.30250692\n",
      "19400 0.30249524\n",
      "19500 0.30248156\n",
      "19600 0.30248237\n",
      "19700 0.3024684\n",
      "19800 0.30245543\n",
      "19900 0.30244607\n",
      "20000 0.30244076\n",
      "20100 0.30243346\n",
      "20200 0.30242538\n",
      "20300 0.30241647\n",
      "20400 0.30240625\n",
      "20500 0.30240068\n",
      "20600 0.30239567\n",
      "20700 0.30238828\n",
      "20800 0.3023847\n",
      "20900 0.3023799\n",
      "21000 0.30236673\n",
      "21100 0.30236873\n",
      "21200 0.30235466\n",
      "21300 0.3023495\n",
      "21400 0.3023455\n",
      "21500 0.30234018\n",
      "21600 0.3023357\n",
      "21700 0.3023248\n",
      "21800 0.30232134\n",
      "21900 0.30231518\n",
      "22000 0.302319\n",
      "22100 0.30231032\n",
      "22200 0.30230224\n",
      "22300 0.30229995\n",
      "22400 0.30229577\n",
      "22500 0.302292\n",
      "22600 0.30228913\n",
      "22700 0.30228508\n",
      "22800 0.30228186\n",
      "22900 0.30228066\n",
      "23000 0.3022698\n",
      "23100 0.30226564\n",
      "23200 0.30226105\n",
      "23300 0.3022611\n",
      "23400 0.30226055\n",
      "23500 0.3022569\n",
      "23600 0.30225405\n",
      "23700 0.3022444\n",
      "23800 0.302246\n",
      "23900 0.30224064\n",
      "24000 0.30224136\n",
      "24100 0.30223796\n",
      "24200 0.30223\n",
      "24300 0.3022222\n",
      "24400 0.3022205\n",
      "24500 0.30221543\n",
      "24600 0.3022107\n",
      "24700 0.30220342\n",
      "24800 0.30220053\n",
      "24900 0.30219454\n",
      "25000 0.30218494\n",
      "25100 0.30217674\n",
      "25200 0.30218053\n",
      "25300 0.30216965\n",
      "25400 0.30216363\n",
      "25500 0.3021632\n",
      "25600 0.3021586\n",
      "25700 0.30215436\n",
      "25800 0.3021488\n",
      "25900 0.30214325\n",
      "26000 0.30214158\n",
      "26100 0.3021303\n",
      "26200 0.30212316\n",
      "26300 0.30211908\n",
      "26400 0.3021124\n",
      "26500 0.3021124\n",
      "26600 0.3021094\n",
      "26700 0.30209917\n",
      "26800 0.30209553\n",
      "26900 0.302094\n",
      "27000 0.30209044\n",
      "27100 0.3020813\n",
      "27200 0.3020756\n",
      "27300 0.30206895\n",
      "27400 0.30206746\n",
      "27500 0.30206317\n",
      "27600 0.3020592\n",
      "27700 0.30205494\n",
      "27800 0.3020484\n",
      "27900 0.30204692\n",
      "28000 0.30204087\n",
      "28100 0.302036\n",
      "28200 0.30203447\n",
      "28300 0.3020256\n",
      "28400 0.3020218\n",
      "28500 0.30201843\n",
      "28600 0.30201238\n",
      "28700 0.3020102\n",
      "28800 0.302005\n",
      "28900 0.30199984\n",
      "29000 0.30199608\n",
      "29100 0.30199233\n",
      "29200 0.30198705\n",
      "29300 0.30198488\n",
      "29400 0.30198562\n",
      "29500 0.3019887\n",
      "29600 0.30198938\n",
      "29700 0.3019894\n",
      "29800 0.30198923\n",
      "29900 0.30198607\n",
      "30000 0.30198574\n",
      "accuracy: 85.50\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed May 16 19:47:19 2018\n",
    "\n",
    "@author: z\n",
    "\n",
    "using CNN\n",
    "\"\"\"\n",
    "\n",
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = pd.read_csv('kobe_data.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x_data = x_data.values\n",
    "y_data = pd.read_csv('kobe_data.csv',usecols=['t1','t2','t3','t4','t5','t6'])\n",
    "y_data = y_data.values\n",
    "\n",
    "x_test = x_data[30000:30600,:]\n",
    "y_test = y_data[30000:30600,:]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([9, 9], -1., 1.))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([9, 6], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([9]))\n",
    "\n",
    "b2 = tf.Variable(tf.zeros([6]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(30000):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if (step + 1) % 100 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "\n",
    "#print('Predicted value:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "#print('Actual value:', sess.run(target, feed_dict={Y: y_test}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('accuracy: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.537771\n",
      "200 0.4975066\n",
      "300 0.46783185\n",
      "400 0.44357392\n",
      "500 0.42356706\n",
      "600 0.40785846\n",
      "700 0.39538762\n",
      "800 0.38558573\n",
      "900 0.378087\n",
      "1000 0.37264606\n",
      "1100 0.36885324\n",
      "1200 0.36620244\n",
      "1300 0.36421576\n",
      "1400 0.36259565\n",
      "1500 0.36118504\n",
      "1600 0.35991248\n",
      "1700 0.35875648\n",
      "1800 0.3576816\n",
      "1900 0.35664517\n",
      "2000 0.3556509\n",
      "2100 0.35468358\n",
      "2200 0.35373676\n",
      "2300 0.3528104\n",
      "2400 0.35192516\n",
      "2500 0.3510962\n",
      "2600 0.35030615\n",
      "2700 0.34953496\n",
      "2800 0.34880677\n",
      "2900 0.3480894\n",
      "3000 0.34739894\n",
      "3100 0.34670988\n",
      "3200 0.34605393\n",
      "3300 0.34542537\n",
      "3400 0.34480608\n",
      "3500 0.34421158\n",
      "3600 0.34364194\n",
      "3700 0.34309107\n",
      "3800 0.3425689\n",
      "3900 0.34206623\n",
      "4000 0.34159023\n",
      "4100 0.341131\n",
      "4200 0.34067994\n",
      "4300 0.3402493\n",
      "4400 0.3398215\n",
      "4500 0.3393923\n",
      "4600 0.3389584\n",
      "4700 0.3385358\n",
      "4800 0.3381269\n",
      "4900 0.33773538\n",
      "5000 0.3373569\n",
      "5100 0.33699\n",
      "5200 0.33664107\n",
      "5300 0.33630598\n",
      "5400 0.33598384\n",
      "5500 0.3356669\n",
      "5600 0.33535567\n",
      "5700 0.3350544\n",
      "5800 0.33476433\n",
      "5900 0.33446828\n",
      "6000 0.33417284\n",
      "6100 0.33387354\n",
      "6200 0.33358085\n",
      "6300 0.33329377\n",
      "6400 0.3329996\n",
      "6500 0.33269486\n",
      "6600 0.33239043\n",
      "6700 0.33208457\n",
      "6800 0.3317857\n",
      "6900 0.33149174\n",
      "7000 0.3312033\n",
      "7100 0.33091992\n",
      "7200 0.33063027\n",
      "7300 0.33034447\n",
      "7400 0.3300564\n",
      "7500 0.32977295\n",
      "7600 0.3294925\n",
      "7700 0.32920915\n",
      "7800 0.3289326\n",
      "7900 0.32866055\n",
      "8000 0.32839262\n",
      "8100 0.3281281\n",
      "8200 0.3278637\n",
      "8300 0.3276013\n",
      "8400 0.32733858\n",
      "8500 0.327076\n",
      "8600 0.3268162\n",
      "8700 0.3265605\n",
      "8800 0.32630232\n",
      "8900 0.3260471\n",
      "9000 0.32579216\n",
      "9100 0.32554483\n",
      "9200 0.32530582\n",
      "9300 0.3250721\n",
      "9400 0.32484344\n",
      "9500 0.32461917\n",
      "9600 0.3243975\n",
      "9700 0.3241778\n",
      "9800 0.3239639\n",
      "9900 0.32375494\n",
      "10000 0.32354823\n",
      "10100 0.32334337\n",
      "10200 0.32314226\n",
      "10300 0.32294786\n",
      "10400 0.322757\n",
      "10500 0.322569\n",
      "10600 0.32238436\n",
      "10700 0.32220146\n",
      "10800 0.32201967\n",
      "10900 0.3218301\n",
      "11000 0.32164487\n",
      "11100 0.32146448\n",
      "11200 0.32128954\n",
      "11300 0.32111806\n",
      "11400 0.32094997\n",
      "11500 0.32077715\n",
      "11600 0.3206047\n",
      "11700 0.3204359\n",
      "11800 0.320269\n",
      "11900 0.32010058\n",
      "12000 0.3199348\n",
      "12100 0.3197745\n",
      "12200 0.31961522\n",
      "12300 0.3194571\n",
      "12400 0.31930122\n",
      "12500 0.31914777\n",
      "12600 0.31899476\n",
      "12700 0.3188437\n",
      "12800 0.31869197\n",
      "12900 0.31854233\n",
      "13000 0.31839302\n",
      "13100 0.31824848\n",
      "13200 0.31810707\n",
      "13300 0.31796342\n",
      "13400 0.31781894\n",
      "13500 0.31767362\n",
      "13600 0.31752762\n",
      "13700 0.31738174\n",
      "13800 0.31723556\n",
      "13900 0.31708997\n",
      "14000 0.31694454\n",
      "14100 0.3167999\n",
      "14200 0.31665683\n",
      "14300 0.31651625\n",
      "14400 0.31637576\n",
      "14500 0.31623575\n",
      "14600 0.3160936\n",
      "14700 0.31595296\n",
      "14800 0.31581444\n",
      "14900 0.31568\n",
      "15000 0.31554264\n",
      "15100 0.3154055\n",
      "15200 0.31527033\n",
      "15300 0.31513724\n",
      "15400 0.3150064\n",
      "15500 0.3148761\n",
      "15600 0.31474626\n",
      "15700 0.3146183\n",
      "15800 0.314491\n",
      "15900 0.31436434\n",
      "16000 0.31423998\n",
      "16100 0.31411603\n",
      "16200 0.3139951\n",
      "16300 0.3138756\n",
      "16400 0.313759\n",
      "16500 0.3136447\n",
      "16600 0.31352994\n",
      "16700 0.31341618\n",
      "16800 0.3133036\n",
      "16900 0.3131924\n",
      "17000 0.31308365\n",
      "17100 0.31297803\n",
      "17200 0.3128748\n",
      "17300 0.31277293\n",
      "17400 0.31267154\n",
      "17500 0.31256932\n",
      "17600 0.31246635\n",
      "17700 0.31236446\n",
      "17800 0.31226406\n",
      "17900 0.3121639\n",
      "18000 0.3120633\n",
      "18100 0.31196487\n",
      "18200 0.311872\n",
      "18300 0.3117824\n",
      "18400 0.31169507\n",
      "18500 0.31161067\n",
      "18600 0.311528\n",
      "18700 0.31144753\n",
      "18800 0.31136766\n",
      "18900 0.3112904\n",
      "19000 0.31121442\n",
      "19100 0.3111391\n",
      "19200 0.31106433\n",
      "19300 0.31099147\n",
      "19400 0.31092045\n",
      "19500 0.31085092\n",
      "19600 0.3107834\n",
      "19700 0.3107169\n",
      "19800 0.31065172\n",
      "19900 0.31058764\n",
      "20000 0.310525\n",
      "20100 0.31046432\n",
      "20200 0.31040382\n",
      "20300 0.31034458\n",
      "20400 0.31028563\n",
      "20500 0.31022707\n",
      "20600 0.3101698\n",
      "20700 0.31011277\n",
      "20800 0.31005657\n",
      "20900 0.3100002\n",
      "21000 0.30994457\n",
      "21100 0.3098894\n",
      "21200 0.30983424\n",
      "21300 0.30977994\n",
      "21400 0.3097261\n",
      "21500 0.30967227\n",
      "21600 0.30961943\n",
      "21700 0.30956662\n",
      "21800 0.3095137\n",
      "21900 0.30946025\n",
      "22000 0.3094084\n",
      "22100 0.30935726\n",
      "22200 0.309306\n",
      "22300 0.30925548\n",
      "22400 0.3092055\n",
      "22500 0.30915678\n",
      "22600 0.30910885\n",
      "22700 0.309062\n",
      "22800 0.3090159\n",
      "22900 0.3089701\n",
      "23000 0.30892476\n",
      "23100 0.3088801\n",
      "23200 0.3088355\n",
      "23300 0.30879194\n",
      "23400 0.30874845\n",
      "23500 0.30870557\n",
      "23600 0.30866274\n",
      "23700 0.30862093\n",
      "23800 0.3085798\n",
      "23900 0.30853954\n",
      "24000 0.30849984\n",
      "24100 0.3084604\n",
      "24200 0.3084208\n",
      "24300 0.30838105\n",
      "24400 0.30834156\n",
      "24500 0.30830273\n",
      "24600 0.3082642\n",
      "24700 0.3082255\n",
      "24800 0.3081872\n",
      "24900 0.30814952\n",
      "25000 0.30811256\n",
      "25100 0.30807608\n",
      "25200 0.3080397\n",
      "25300 0.3080034\n",
      "25400 0.30796617\n",
      "25500 0.30792972\n",
      "25600 0.30789343\n",
      "25700 0.30785677\n",
      "25800 0.3078208\n",
      "25900 0.30778542\n",
      "26000 0.30775046\n",
      "26100 0.3077157\n",
      "26200 0.30768186\n",
      "26300 0.3076481\n",
      "26400 0.30761504\n",
      "26500 0.30758175\n",
      "26600 0.30754873\n",
      "26700 0.30751613\n",
      "26800 0.30748364\n",
      "26900 0.30745187\n",
      "27000 0.30742034\n",
      "27100 0.30738902\n",
      "27200 0.30735824\n",
      "27300 0.30732745\n",
      "27400 0.3072969\n",
      "27500 0.30726656\n",
      "27600 0.30723664\n",
      "27700 0.30720705\n",
      "27800 0.3071776\n",
      "27900 0.30714846\n",
      "28000 0.30711958\n",
      "28100 0.3070911\n",
      "28200 0.3070626\n",
      "28300 0.30703515\n",
      "28400 0.30700728\n",
      "28500 0.30698043\n",
      "28600 0.3069536\n",
      "28700 0.30692607\n",
      "28800 0.30689898\n",
      "28900 0.30687228\n",
      "29000 0.3068459\n",
      "29100 0.30681992\n",
      "29200 0.30679405\n",
      "29300 0.30676836\n",
      "29400 0.30674124\n",
      "29500 0.3067156\n",
      "29600 0.30669025\n",
      "29700 0.30666506\n",
      "29800 0.3066396\n",
      "29900 0.30661455\n",
      "30000 0.30658954\n",
      "accuracy: 85.83\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed May 16 19:47:19 2018\n",
    "\n",
    "@author: z\n",
    "\n",
    "using CNN\n",
    "\"\"\"\n",
    "\n",
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = pd.read_csv('kobe_data.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x_data = x_data.values\n",
    "y_data = pd.read_csv('kobe_data.csv',usecols=['t1','t2','t3','t4','t5','t6'])\n",
    "y_data = y_data.values\n",
    "\n",
    "x_test = x_data[30000:30600,:]\n",
    "y_test = y_data[30000:30600,:]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([9, 3], -1., 1.))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([3, 6], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "b2 = tf.Variable(tf.zeros([6]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(30000):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if (step + 1) % 100 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "\n",
    "#print('Predicted value:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "#print('Actual value:', sess.run(target, feed_dict={Y: y_test}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('accuracy: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.33286336\n",
      "2000 0.30836788\n",
      "3000 0.30534348\n",
      "4000 0.30412433\n",
      "5000 0.303533\n",
      "6000 0.303235\n",
      "7000 0.30303422\n",
      "8000 0.30288857\n",
      "9000 0.3027758\n",
      "10000 0.30268985\n",
      "11000 0.30262467\n",
      "12000 0.30257955\n",
      "13000 0.3025384\n",
      "14000 0.3025092\n",
      "15000 0.30248767\n",
      "16000 0.3024575\n",
      "17000 0.30244136\n",
      "18000 0.30241883\n",
      "19000 0.30239433\n",
      "20000 0.30237284\n",
      "21000 0.30236617\n",
      "22000 0.30234957\n",
      "23000 0.30235136\n",
      "24000 0.3023353\n",
      "25000 0.30231956\n",
      "26000 0.30231386\n",
      "27000 0.30230486\n",
      "28000 0.30229524\n",
      "29000 0.30228764\n",
      "30000 0.30227217\n",
      "accuracy: 88.82\n"
     ]
    }
   ],
   "source": [
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = pd.read_csv('kobe_data.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x_data = x_data.values\n",
    "y_data = pd.read_csv('kobe_data.csv',usecols=['t1','t2','t3','t4','t5','t6'])\n",
    "y_data = y_data.values\n",
    "\n",
    "x_test = x_data[25000:30600,:]\n",
    "y_test = y_data[25000:30600,:]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([9, 9], -1., 1.))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([9, 6], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([9]))\n",
    "\n",
    "b2 = tf.Variable(tf.zeros([6]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(30000):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if (step + 1) % 1000 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "\n",
    "#print('Predicted value:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "#print('Actual value:', sess.run(target, feed_dict={Y: y_test}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('accuracy: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.32776612\n",
      "2000 0.29822546\n",
      "3000 0.28945595\n",
      "4000 0.2854652\n",
      "5000 0.2841113\n",
      "6000 0.28208718\n",
      "7000 0.28140458\n",
      "8000 0.28157\n",
      "9000 0.28113422\n",
      "10000 0.2814775\n",
      "11000 0.2812075\n",
      "12000 0.281309\n",
      "13000 0.28136882\n",
      "14000 0.28124171\n",
      "15000 0.28137872\n",
      "16000 0.28123856\n",
      "17000 0.28099328\n",
      "18000 0.28100932\n",
      "19000 0.2809997\n",
      "20000 0.2809856\n",
      "21000 0.28088838\n",
      "22000 0.28096858\n",
      "23000 0.28089592\n",
      "24000 0.28091\n",
      "25000 0.28074345\n",
      "26000 0.2806847\n",
      "27000 0.2806627\n",
      "28000 0.28072613\n",
      "29000 0.28065097\n",
      "30000 0.28065223\n",
      "accuracy: 86.54\n"
     ]
    }
   ],
   "source": [
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "x = pd.read_csv('kobe_data.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x =x.values\n",
    "y = pd.read_csv('kobe_data.csv',usecols=['t1','t2','t3','t4','t5','t6'])\n",
    "y = y.values\n",
    "\n",
    "x_data = x[5000:30600,:]\n",
    "y_data = y[5000:30600,:]\n",
    "\n",
    "\n",
    "x_test = x[0:5000,:]\n",
    "y_test = y[0:5000,:]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([9, 9], -1., 1.))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([9, 6], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([9]))\n",
    "\n",
    "b2 = tf.Variable(tf.zeros([6]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "model = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(30000):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if (step + 1) % 1000 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "\n",
    "#print('Predicted value:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "#print('Actual value:', sess.run(target, feed_dict={Y: y_test}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('accuracy: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.7729189\n",
      "2000 0.75060385\n",
      "3000 0.7493384\n",
      "4000 0.7490172\n",
      "5000 0.74889296\n",
      "6000 0.74883604\n",
      "7000 0.7488355\n",
      "8000 0.7488211\n",
      "9000 0.748833\n",
      "10000 0.7488179\n",
      "11000 0.7488175\n",
      "12000 0.7488156\n",
      "13000 0.7488228\n",
      "14000 0.7488231\n",
      "15000 0.7488273\n",
      "16000 0.7488281\n",
      "17000 0.7488272\n",
      "18000 0.748828\n",
      "19000 0.7488282\n",
      "20000 0.7488284\n",
      "21000 0.74878955\n",
      "22000 0.7487892\n",
      "23000 0.7487894\n",
      "24000 0.7487899\n",
      "25000 0.74879044\n",
      "26000 0.7487905\n",
      "27000 0.74879044\n",
      "28000 0.74879026\n",
      "29000 0.74879026\n",
      "30000 0.7487902\n",
      "accuracy: 71.20\n"
     ]
    }
   ],
   "source": [
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "x = pd.read_csv('kobe_data.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x =x.values\n",
    "y = pd.read_csv('kobe_data.csv',usecols=['t1','t2','t3','t4','t5','t6'])\n",
    "y = y.values\n",
    "\n",
    "x_data = x[5000:30600,:]\n",
    "y_data = y[5000:30600,:]\n",
    "\n",
    "\n",
    "x_test = x[0:5000,:]\n",
    "y_test = y[0:5000,:]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([9, 8], -1., 1.))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([8, 7], -1., 1.))\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform([7, 6], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([8]))\n",
    "\n",
    "b2 = tf.Variable(tf.zeros([7]))\n",
    "\n",
    "b3 = tf.Variable(tf.zeros([6]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, W1), b1)\n",
    "\n",
    "L2 = tf.add(tf.matmul(L1, W2), b2)\n",
    "\n",
    "L2 = tf.nn.relu(L2)\n",
    "\n",
    "model = tf.add(tf.matmul(L2, W3), b3)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(30000):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if (step + 1) % 1000 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "\n",
    "#print('Predicted value:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "#print('Actual value:', sess.run(target, feed_dict={Y: y_test}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('accuracy: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.35644096\n",
      "2000 0.34655938\n",
      "3000 0.34314987\n",
      "4000 0.34218627\n",
      "5000 0.34173942\n",
      "6000 0.34140763\n",
      "7000 0.3411248\n",
      "8000 0.34087765\n",
      "9000 0.34065986\n",
      "10000 0.34046677\n",
      "11000 0.34029418\n",
      "12000 0.34013885\n",
      "13000 0.3399987\n",
      "14000 0.33987153\n",
      "15000 0.33975592\n",
      "16000 0.33965087\n",
      "17000 0.33955482\n",
      "18000 0.3394681\n",
      "19000 0.33938888\n",
      "20000 0.33931625\n",
      "21000 0.33924964\n",
      "22000 0.3391887\n",
      "23000 0.33913317\n",
      "24000 0.33908325\n",
      "25000 0.33903745\n",
      "26000 0.3389955\n",
      "27000 0.33895692\n",
      "28000 0.33892208\n",
      "29000 0.33889022\n",
      "30000 0.33886078\n",
      "accuracy: 86.68\n"
     ]
    }
   ],
   "source": [
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "x = pd.read_csv('kobe_data.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x =x.values\n",
    "y = pd.read_csv('kobe_data.csv',usecols=['t1','t2','t3','t4','t5','t6'])\n",
    "y = y.values\n",
    "\n",
    "x_data = x[5000:30600,:]\n",
    "y_data = y[5000:30600,:]\n",
    "\n",
    "\n",
    "x_test = x[0:5000,:]\n",
    "y_test = y[0:5000,:]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([9, 6], -1., 1.))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([6]))\n",
    "\n",
    "model = tf.add(tf.matmul(X, W1), b1)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(30000):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if (step + 1) % 1000 == 0:\n",
    "        print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "\n",
    "#print('Predicted value:', sess.run(prediction, feed_dict={X: x_test}))\n",
    "#print('Actual value:', sess.run(target, feed_dict={Y: y_test}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('accuracy: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         2\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       1.00      1.00      1.00        10\n",
      "\n",
      "[[2 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 2 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "x_data = pd.read_csv('kobe_minidata.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x_data = x_data.values\n",
    "y_data = pd.read_csv('kobe_minidata.csv',usecols=['action_type'])\n",
    "y_data = y_data.values\n",
    "#print(x_data)\n",
    "#print(y_data)\n",
    "\n",
    "x_test = x_data[0:100:10,:]\n",
    "y_test = y_data[0:100:10,:]\n",
    "#print(y_test)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_data,y_data)\n",
    "print(model)\n",
    "\n",
    "expected = y_test\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(expected,predicted))\n",
    "print(metrics.confusion_matrix(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93       714\n",
      "          1       0.53      0.63      0.57       202\n",
      "          2       0.18      0.07      0.10        58\n",
      "          3       0.00      0.00      0.00         8\n",
      "          4       0.33      0.06      0.10        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.78      0.80      0.79      1000\n",
      "\n",
      "[[667  41   0   0   0   6]\n",
      " [ 53 127  14   6   1   1]\n",
      " [  0  52   4   1   1   0]\n",
      " [  0   6   2   0   0   0]\n",
      " [  0  14   2   0   1   0]\n",
      " [  0   1   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "x = pd.read_csv('kobe_data.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x = x.values\n",
    "y = pd.read_csv('kobe_data.csv',usecols=['action_type'])\n",
    "y = y.values\n",
    "\n",
    "#print(x_data)\n",
    "#print(y_data)\n",
    "x_data = x[1001:30000,:]\n",
    "y_data = y[1001:30000,:]\n",
    "x_test = x[0:1000,:]\n",
    "y_test = y[0:1000,:]\n",
    "#print(y_test)\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='gini',splitter='random',max_features=None)\n",
    "#criterion='gini'\\'entropy',splitter='random'\\'best',\n",
    "model.fit(x_data,y_data)\n",
    "print(model)\n",
    "\n",
    "expected = y_test\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(expected,predicted))\n",
    "print(metrics.confusion_matrix(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       714\n",
      "          1       0.63      0.59      0.61       202\n",
      "          2       0.23      0.10      0.14        58\n",
      "          3       0.00      0.00      0.00         8\n",
      "          4       1.00      0.06      0.11        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.81      0.84      0.82      1000\n",
      "\n",
      "[[711   3   0   0   0   0]\n",
      " [ 63 120  14   5   0   0]\n",
      " [  0  50   6   2   0   0]\n",
      " [  0   5   3   0   0   0]\n",
      " [  1  13   2   0   1   0]\n",
      " [  0   0   1   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "x = pd.read_csv('kobe_data.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x = x.values\n",
    "y = pd.read_csv('kobe_data.csv',usecols=['action_type'])\n",
    "y = y.values\n",
    "\n",
    "#print(x_data)\n",
    "#print(y_data)\n",
    "x_data = x[1001:30000,:]\n",
    "y_data = y[1001:30000,:]\n",
    "x_test = x[0:1000,:]\n",
    "y_test = y[0:1000,:]\n",
    "#print(y_test)\n",
    "\n",
    "model = RandomForestClassifier(max_features=None,n_estimators=100)\n",
    "model.fit(x_data,y_data)\n",
    "print(model)\n",
    "\n",
    "expected = y_test\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(expected,predicted))\n",
    "print(metrics.confusion_matrix(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96       714\n",
      "          1       0.62      0.68      0.65       202\n",
      "          2       0.00      0.00      0.00        58\n",
      "          3       0.00      0.00      0.00         8\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.78      0.85      0.81      1000\n",
      "\n",
      "[[713   1   0   0   0   0]\n",
      " [ 65 137   0   0   0   0]\n",
      " [  0  58   0   0   0   0]\n",
      " [  0   8   0   0   0   0]\n",
      " [  1  16   0   0   0   0]\n",
      " [  0   1   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "x = pd.read_csv('kobe_data.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x = x.values\n",
    "y = pd.read_csv('kobe_data.csv',usecols=['action_type'])\n",
    "y = y.values\n",
    "\n",
    "#print(x_data)\n",
    "#print(y_data)\n",
    "x_data = x[1001:30000,:]\n",
    "y_data = y[1001:30000,:]\n",
    "x_test = x[0:1000,:]\n",
    "y_test = y[0:1000,:]\n",
    "#print(y_test)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100,learning_rate=0.1)\n",
    "model.fit(x_data,y_data)\n",
    "print(model)\n",
    "\n",
    "expected = y_test\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(expected,predicted))\n",
    "print(metrics.confusion_matrix(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.1, n_estimators=100, random_state=None)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       714\n",
      "          1       0.59      0.70      0.64       202\n",
      "          2       0.00      0.00      0.00        58\n",
      "          3       0.00      0.00      0.00         8\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.78      0.84      0.81      1000\n",
      "\n",
      "[[699  15   0   0   0   0]\n",
      " [ 61 141   0   0   0   0]\n",
      " [  0  58   0   0   0   0]\n",
      " [  0   8   0   0   0   0]\n",
      " [  1  16   0   0   0   0]\n",
      " [  0   1   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#kobe_dataset\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "x = pd.read_csv('kobe_data.csv',usecols=['loc_x','loc_y','shot_distance',\n",
    "'shot_zone_area','playoffs','period','minutes_remaining','seconds_remaining',\n",
    "'shot_type'])\n",
    "\n",
    "x = x.values\n",
    "y = pd.read_csv('kobe_data.csv',usecols=['action_type'])\n",
    "y = y.values\n",
    "\n",
    "#print(x_data)\n",
    "#print(y_data)\n",
    "x_data = x[1001:30000,:]\n",
    "y_data = y[1001:30000,:]\n",
    "x_test = x[0:1000,:]\n",
    "y_test = y[0:1000,:]\n",
    "#print(y_test)\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=100,learning_rate=0.1)\n",
    "model.fit(x_data,y_data)\n",
    "print(model)\n",
    "\n",
    "expected = y_test\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(expected,predicted))\n",
    "print(metrics.confusion_matrix(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
